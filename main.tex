\documentclass[letterpaper]{article}
\usepackage{uai2020}
\usepackage[margin=1in]{geometry}

\usepackage[sort&compress,numbers]{natbib}

\usepackage{times}

\usepackage[autonum]{tchdr}
\usepackage{tikz}
\usetikzlibrary{bayesnet}
\newcommand{\tre}{\cdots}
\newcommand{\Qexp}{\mcQ^\text{exp}}
\newcommand{\Qfull}{\mcQ^\text{full}}
\newcommand{\kgibbs}{K^\text{Gibbs}}
\newcommand{\kbgibbs}{K^\text{blockGibbs}}
\newcommand{\todo}{\textcolor{red}{\text{continue???}}}


\title{On Truncation of  Completely Random Measure Mixture Models}

\author{ 
{\{\bf{Boyan Beronov} \quad \bf {Christian Weilbach}\} \qquad \bf {Peiyuan Zhu}}  \\
\qquad\qquad Department of Computer Science  \qquad Department of Statistics \\
University of British Columbia\\
Vancouver, BC V6T 1Z4 \\
}

\begin{document}

\maketitle
\section{Introduction}

\section{Background}
In trait allocation models, it is common use unnormalized completely random measure as prior.  The generative model with likelihood $f$ and unnormalized completely random measure with rate measure $\nu$ and base distribution $H$ as prior can be written as:
\[
\Theta&=\sum_k\theta_k\delta_{\psi_k}\dist\distCRM(\nu,H)\cr
X_n&\distiid\distLP(h,\Theta)\cr
Y_n|X_n&\distind f(\cdot|X_n)\label{eq:crm}
\]
where $X_n$ captures to what extend data $n$ exhibit each trait and $Y_n$ is the data. In clustering, it is common to use normalized completely random measure as prior. The generative model with likelihood $f$ and normalized completely random measure with rate measure $\nu$ and base distribution $H$ as prior can be written as:
\[
	\Theta&=\sum_k\theta_k\delta_{\psi_k}\dist\distCRM(\nu,H)\cr
	\Xi&=\frac{\Theta}{\Theta(\Psi)}\cr
	X_n&\distiid\Xi\cr
	Y_n|X_n&\distind f(\cdot|X_n)\label{eq:ncrm}
\]
where $X_n$ is the cluster assignment variable and $Y_n$ is the data. 

We define space of marginal likelihood i.e. integrating out $\Theta$ as the information manifold:
\[
	\mcM=\left\{\EE\left[\prod_{n=1}^Nf(y_n|X_n)\right]:\text{ for }y\in\cup_\psi\supp(f(\cdot|\psi))\right\}
\]

Let the marginal likelihood of the infinite model be $p_{N,\infty}$ and the marginal likelihood of the truncated model at level $K$ be $p_{N,K}$. \cite{nguyen20} and \cite{campbell19} derived error bounds in total variation norm on different truncation methods. 

{
\small
\bibliographystyle{unsrtnat}
\bibliography{sources}
}

\appendix
\end{document}
\typeout{get arXiv to do 4 passes: Label(s) may have changed. Rerun}
